{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COunt of cases & \n",
    "countries = ['Austria', 'Belgium', 'Switzerland', 'Cyprus', 'Germany', 'Denmark', 'Spain', 'France', 'Greece', 'Italy', 'Ireland', 'Iceland', 'Luxemburg', 'Malta', 'Norway', \n",
    "             'Netherlands', 'Portugal', 'Sweden', 'Finland', 'Turkey', 'United Kingdom', 'Albania', 'Andorra', 'Armenia', 'Azerbaijan', 'Bulgaria', 'Croatia', 'Czech Republic', \n",
    "             'Estonia', 'Georgia', 'Hungary', 'Latvia', 'Liechtenstein', 'Lithuania', 'Moldova', 'Poland', 'Romania', 'Russia', 'San Marino', 'Slovakia', 'Slovenia', 'North Macedonia', \n",
    "             'Ukraine', 'Bosnia Herzegovina', 'Serbia and Montenegro', 'Monaco', 'Montenegro', 'Serbia']\n",
    "\n",
    "\n",
    "text = \"Afghanistan, Akrotiri and Dhekelia, Åland, Albania, Algeria, American Samoa, Andorra, Angola, Anguilla, Antigua and Barbuda, Argentina, Armenia, Aruba, Australia, Austria, Azerbaijan Bahamas, Bahrain, Bangladesh, Barbados, Belarus, Belgium, Belize, Benin, Bermuda, Bhutan, Bolivia, Bonaire, Saint Eustatius and Saba, Bosnia and Herzegovina, Botswana, Bouvet Island, Brazil, British Indian Ocean Territory, British Virgin Islands, Brunei, Bulgaria, Burkina Faso, Burundi Cambodia, Cameroon, Canada, Cabo Verde, Caspian Sea, Cayman Islands, Central African Republic, Chad, Chile, China, Christmas Island, Clipperton Island, Cocos Islands, Colombia, Comoros, Cook Islands, Costa Rica, Côte d’Ivoire, Croatia, Cuba, Curaçao, Cyprus, Czechia Democratic Republic of the Congo, Denmark, Djibouti, Dominica, Dominican Republic Ecuador, Egypt, El Salvador, Equatorial Guinea, Eritrea, Estonia, Ethiopia Falkland Islands, Faroe Islands, Fiji, Finland, France, French Guiana, French Polynesia, French Southern Territories Gabon, Gambia, Georgia, Germany, Ghana, Gibraltar, Greece, Greenland, Grenada, Guadeloupe, Guam, Guatemala, Guernsey, Guinea, Guinea-Bissau, Guyana Haiti, Heard Island and McDonald Islands, Honduras, Hong Kong, Hungary Iceland, India, Indonesia, Iran, Iraq, Ireland, Isle of Man, Israel, Italy Jamaica, Japan, Jersey, Jordan Kazakhstan, Kenya, Kiribati, Kosovo, Kuwait, Kyrgyzstan Laos, Latvia, Lebanon, Lesotho, Liberia, Libya, Liechtenstein, Lithuania, Luxembourg Macao, Macedonia, Madagascar, Malawi, Malaysia, Maldives, Mali, Malta, Marshall Islands, Martinique, Mauritania, Mauritius, Mayotte, Mexico, Micronesia, Moldova, Monaco, Mongolia, Montenegro, Montserrat, Morocco, Mozambique, Myanmar Namibia, Nauru, Nepal, Netherlands, New Caledonia, New Zealand, Nicaragua, Niger, Nigeria, Niue, Norfolk Island, North Korea, Northern Cyprus, Northern Mariana Islands, Norway Oman Pakistan, Palau, Palestine, Panama, Papua New Guinea, Paraguay, Peru, Philippines, Pitcairn Islands, Poland, Portugal, Puerto Rico Qatar Republic of the Congo, Réunion, Romania, Russia, Rwanda Saint-Barthélemy, Saint-Martin, Saint Helena, Ascension and Tristan da Cunha, Saint Kitts and Nevis, Saint Lucia, Saint Pierre and Miquelon, Saint Vincent and the Grenadines, Samoa, San Marino, São Tomé and Príncipe, Saudi Arabia, Senegal, Serbia, Seychelles, Sierra Leone, Singapore, Slovakia, Slovenia, Solomon Islands, Somalia, South Africa, South Georgia and the South Sandwich Islands, South Korea, South Sudan, Spain, Sri Lanka, Sudan, Suriname, Svalbard and Jan Mayen, Swaziland, Sweden, Switzerland, Syria Taiwan, Tajikistan, Tanzania, Thailand, Timor-Leste, Togo, Tokelau, Tonga, Trinidad and Tobago, Tunisia, Turkey, Turkmenistan, Turks and Caicos Islands, Tuvalu Uganda, Ukraine, United Arab Emirates, United Kingdom, United States, United States Minor Outlying Islands, Uruguay, Uzbekistan Vanuatu, Vatican City, Venezuela, Vietnam, Virgin Islands, U.S. Wallis and Futuna, Western Sahara Yemen Zambia, Zimbabwe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries not found in the text: ['Luxemburg', 'Czech Republic', 'North Macedonia', 'Bosnia Herzegovina', 'Serbia and Montenegro']\n"
     ]
    }
   ],
   "source": [
    "found_countries = []\n",
    "not_found_countries = []\n",
    "\n",
    "for country in countries:\n",
    "    if country in text:\n",
    "        found_countries.append(country)\n",
    "    else:\n",
    "        not_found_countries.append(country)\n",
    "\n",
    "print(\"Countries not found in the text:\", not_found_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_countries_df = pd.DataFrame(found_countries, columns=[\"Country\"])\n",
    "\n",
    "found_countries_df.to_excel('Output/countries.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined GeoJSON saved to output\\combined.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "json_files = [\"belgium.json\", \"cyprus.json\", \"austria.json\", \"switzerland.json\", \"germany.json\",\n",
    "              \"denmark.json\", \"spain.json\", \"france.json\", \"greece.json\", \"italy.json\", \"ireland.json\",\n",
    "              \"iceland.json\", \"malta.json\", \"norway.json\", \"netherlands.json\", \"portugla.json\", \"sweden.json\",\n",
    "              \"findland.json\", \"turkey.json\", \"united_kingdom.json\", \"albania.json\", \"andorra.json\", \n",
    "              \"armenia.json\", \"azerbaijan.json\", \"bulgaria.json\", \"croatia.json\", \"estonia.json\", \"georgia.json\",\n",
    "              \"hungary.json\", \"latvia.json\", \"liechtenstein.json\", \"lithuania.json\", \"moldova.json\", \"poland.json\",\n",
    "              \"romania.json\", \"russia.json\", \"san_marino.json\", \"slovakia.json\", \"slovenia.json\", \"ukraine.json\",\n",
    "              \"monaco.json\", \"montenegro.json\", \"macedonia.json\", \"bosnia_herzegovina.json\", \"luxemburg.json\",\n",
    "              \"czech_republic.json\", \"serbia.json\"]\n",
    "\n",
    "data_dir = \"country_shp\"\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(data_dir, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        if 'features' in data:\n",
    "            all_features.extend(data['features'])\n",
    "\n",
    "combined_geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": all_features\n",
    "}\n",
    "\n",
    "output_dir = \"output\"\n",
    "output_file = os.path.join(output_dir, \"combined.json\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(combined_geojson, f, indent=4)\n",
    "\n",
    "print(f\"Combined GeoJSON saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = pd.read_excel('Output/business_up_to_2022.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_dict = {\n",
    "    1: 'Austria', 2: 'Belgium', 3: 'Switzerland', 4: 'Cyprus', 5: 'Germany', 6: 'Denmark', 7: 'Spain',\n",
    "    8: 'France', 9: 'Greece', 10: 'Italy', 11: 'Ireland', 12: 'Iceland', 13: 'Luxembourg', 14: 'Malta',\n",
    "    15: 'Norway', 16: 'Netherlands', 17: 'Portugal', 18: 'Sweden', 19: 'Finland', 20: 'Turkey', 21: 'United Kingdom',\n",
    "    22: 'Albania', 23: 'Andorra', 24: 'Armenia', 25: 'Azerbaijan', 26: 'Bulgaria', 27: 'Croatia', 28: 'Czech Republic',\n",
    "    29: 'Estonia', 30: 'Georgia', 31: 'Hungary', 32: 'Latvia', 33: 'Liechtenstein', 34: 'Lithuania', 35: 'Moldova',\n",
    "    36: 'Poland', 37: 'Romania', 38: 'Russia', 39: 'San Marino', 40: 'Slovakia', 41: 'Slovenia', 42: 'North Macedonia',\n",
    "    43: 'Ukraine', 44: 'Bosnia Herzegovina', 46: 'Monaco', 47: 'Montenegro', 48: 'Serbia'\n",
    "}\n",
    "\n",
    "business_df= business_df[business_df[\"BUS\"] == 1]\n",
    "\n",
    "business_df['country1'] = business_df['country1'].map(country_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 conclusions\n",
      "1 casetitle\n",
      "2 case\n",
      "3 app\n",
      "4 joinedapp\n",
      "5 BUS\n",
      "6 dtejmt\n",
      "7 dtelgd\n",
      "8 date\n",
      "9 impt\n",
      "10 country1\n",
      "11 country2\n",
      "12 country3\n",
      "13 country4\n",
      "14 country5\n",
      "15 country6\n",
      "16 country7\n",
      "17 decision\n",
      "18 art2\n",
      "19 art3\n",
      "20 art4\n",
      "21 art5\n",
      "22 art6\n",
      "23 art7\n",
      "24 art8\n",
      "25 art9\n",
      "26 art10\n",
      "27 art11\n",
      "28 art12\n",
      "29 art13\n",
      "30 art14\n",
      "31 art17\n",
      "32 art18\n",
      "33 art25\n",
      "34 art34\n",
      "35 art38\n",
      "36 art46\n",
      "37 p1a1\n",
      "38 p1a2\n",
      "39 p1a3\n",
      "40 p4a2\n",
      "41 p4a3\n",
      "42 p4a4\n",
      "43 p6a1\n",
      "44 p7a1\n",
      "45 p7a2\n",
      "46 p7a3\n",
      "47 p7a4\n",
      "48 p7a5\n",
      "49 p12a1\n",
      "50 partid1\n",
      "51 partid2\n",
      "52 partid3\n",
      "53 partid4\n",
      "54 partid5\n",
      "55 partid6\n",
      "56 partid7\n",
      "57 partid8\n",
      "58 partid9\n",
      "59 partid10\n",
      "60 partid11\n",
      "61 partid12\n",
      "62 partid13\n",
      "63 partid14\n",
      "64 partid15\n",
      "65 partid16\n",
      "66 partid17\n",
      "67 partid18\n",
      "68 partid19\n",
      "69 partid20\n",
      "70 partid21\n",
      "71 partid22\n",
      "72 partid23\n",
      "73 partid24\n",
      "74 partid25\n",
      "75 partid26\n",
      "76 partid27\n",
      "77 partid28\n",
      "78 partid29\n",
      "79 partid30\n",
      "80 partid31\n",
      "81 partid32\n",
      "82 partid33\n",
      "83 partid34\n",
      "84 partid35\n",
      "85 partid36\n",
      "86 partid37\n",
      "87 partid38\n",
      "88 partid39\n",
      "89 partid40\n",
      "90 partid41\n",
      "91 partid42\n",
      "92 partid43\n",
      "93 partid44\n",
      "94 partid45\n",
      "95 partid46\n",
      "96 partid47\n",
      "97 inttype1\n",
      "98 inttype2\n",
      "99 inttype3\n",
      "100 inttype4\n",
      "101 inttype5\n",
      "102 inttype6\n",
      "103 inttype7\n",
      "104 inttype8\n",
      "105 inttype9\n",
      "106 inttype10\n",
      "107 inttype11\n",
      "108 inttype12\n",
      "109 inttype13\n",
      "110 inttype14\n",
      "111 inttype15\n",
      "112 inttype16\n",
      "113 inttype17\n",
      "114 inttype18\n",
      "115 inttype19\n",
      "116 inttype20\n",
      "117 inttype21\n",
      "118 inttype22\n",
      "119 inttype23\n",
      "120 inttype24\n",
      "121 inttype25\n",
      "122 inttype26\n",
      "123 inttype27\n",
      "124 inttype28\n",
      "125 inttype29\n",
      "126 inttype30\n",
      "127 inttype31\n",
      "128 inttype32\n",
      "129 inttype33\n",
      "130 inttype34\n",
      "131 inttype35\n",
      "132 inttype36\n",
      "133 inttype37\n",
      "134 inttype38\n",
      "135 inttype39\n",
      "136 inttype40\n",
      "137 inttype41\n",
      "138 inttype42\n",
      "139 inttype43\n",
      "140 inttype44\n",
      "141 inttype45\n",
      "142 inttype46\n",
      "143 inttype47\n",
      "144 partmode1\n",
      "145 partmode2\n",
      "146 partmode3\n",
      "147 partmode4\n",
      "148 partmode5\n",
      "149 partmode6\n",
      "150 partmode7\n",
      "151 partmode8\n",
      "152 partmode9\n",
      "153 partmode10\n",
      "154 partmode11\n",
      "155 partmode12\n",
      "156 partmode13\n",
      "157 partmode14\n",
      "158 partmode15\n",
      "159 partmode16\n",
      "160 partmode17\n",
      "161 partmode18\n",
      "162 partmode19\n",
      "163 partmode20\n",
      "164 partmode21\n",
      "165 partmode22\n",
      "166 partmode23\n",
      "167 partmode24\n",
      "168 partmode25\n",
      "169 partmode26\n",
      "170 partmode27\n",
      "171 partmode28\n",
      "172 partmode29\n",
      "173 partmode30\n",
      "174 partmode31\n",
      "175 partmode32\n",
      "176 partmode33\n",
      "177 partmode34\n",
      "178 partmode35\n",
      "179 partmode36\n",
      "180 partmode37\n",
      "181 partmode38\n",
      "182 partmode39\n",
      "183 partmode40\n",
      "184 partmode41\n",
      "185 partmode42\n",
      "186 partmode43\n",
      "187 partmode44\n",
      "188 partmode45\n",
      "189 partmode46\n",
      "190 partmode47\n",
      "191 summ1\n",
      "192 summ2\n",
      "193 summ3\n",
      "194 summ4\n",
      "195 summ5\n",
      "196 summ6\n",
      "197 summ7\n",
      "198 summ8\n",
      "199 summ9\n",
      "200 summ10\n",
      "201 summ11\n",
      "202 summ12\n",
      "203 summ13\n",
      "204 summ14\n",
      "205 summ15\n",
      "206 summ16\n",
      "207 summ17\n",
      "208 summ18\n",
      "209 summ19\n",
      "210 summ20\n",
      "211 summ21\n",
      "212 summ22\n",
      "213 engapp1\n",
      "214 engapp2\n",
      "215 engapp3\n",
      "216 engapp4\n",
      "217 engapp5\n",
      "218 engapp6\n",
      "219 engapp7\n",
      "220 engapp8\n",
      "221 engapp9\n",
      "222 engapp10\n",
      "223 engapp11\n",
      "224 engapp12\n",
      "225 engapp13\n",
      "226 engapp14\n",
      "227 engapp15\n",
      "228 engapp16\n",
      "229 engapp17\n",
      "230 engapp18\n",
      "231 engapp19\n",
      "232 engapp20\n",
      "233 engapp21\n",
      "234 engapp22\n",
      "235 engstate1\n",
      "236 engstate2\n",
      "237 engstate3\n",
      "238 engstate4\n",
      "239 engstate5\n",
      "240 engstate6\n",
      "241 engstate7\n",
      "242 engstate8\n",
      "243 engstate9\n",
      "244 engstate10\n",
      "245 engstate11\n",
      "246 engstate12\n",
      "247 engstate13\n",
      "248 engstate14\n",
      "249 engstate15\n",
      "250 engstate16\n",
      "251 engstate17\n",
      "252 engstate18\n",
      "253 engstate19\n",
      "254 engstate20\n",
      "255 engstate21\n",
      "256 engstate22\n",
      "257 engcourt1\n",
      "258 engcourt2\n",
      "259 engcourt3\n",
      "260 engcourt4\n",
      "261 engcourt5\n",
      "262 engcourt6\n",
      "263 engcourt7\n",
      "264 engcourt8\n",
      "265 engcourt9\n",
      "266 engcourt10\n",
      "267 engcourt11\n",
      "268 engcourt12\n",
      "269 engcourt13\n",
      "270 engcourt14\n",
      "271 engcourt15\n",
      "272 engcourt16\n",
      "273 engcourt17\n",
      "274 engcourt18\n",
      "275 engcourt19\n",
      "276 engcourt20\n",
      "277 engcourt21\n",
      "278 engcourt22\n",
      "279 engdiss1\n",
      "280 engdiss2\n",
      "281 engdiss3\n",
      "282 engdiss4\n",
      "283 engdiss5\n",
      "284 engdiss6\n",
      "285 engdiss7\n",
      "286 engdiss8\n",
      "287 engdiss9\n",
      "288 engdiss10\n",
      "289 engdiss11\n",
      "290 engdiss12\n",
      "291 engdiss13\n",
      "292 engdiss14\n",
      "293 engdiss15\n",
      "294 engdiss16\n",
      "295 engdiss17\n",
      "296 engdiss18\n",
      "297 engdiss19\n",
      "298 engdiss20\n",
      "299 engdiss21\n",
      "300 engdiss22\n",
      "301 engcon1\n",
      "302 engcon2\n",
      "303 engcon3\n",
      "304 engcon4\n",
      "305 engcon5\n",
      "306 engcon6\n",
      "307 engcon7\n",
      "308 engcon8\n",
      "309 engcon9\n",
      "310 engcon10\n",
      "311 engcon11\n",
      "312 engcon12\n",
      "313 engcon13\n",
      "314 engcon14\n",
      "315 engcon15\n",
      "316 engcon16\n",
      "317 engcon17\n",
      "318 engcon18\n",
      "319 engcon19\n",
      "320 engcon20\n",
      "321 engcon21\n",
      "322 engcon22\n",
      "323 suptpi1\n",
      "324 suptpi2\n",
      "325 suptpi3\n",
      "326 suptpi4\n",
      "327 suptpi5\n",
      "328 suptpi6\n",
      "329 suptpi7\n",
      "330 suptpi8\n",
      "331 suptpi9\n",
      "332 suptpi10\n",
      "333 suptpi11\n",
      "334 suptpi12\n",
      "335 suptpi13\n",
      "336 suptpi14\n",
      "337 suptpi15\n",
      "338 suptpi16\n",
      "339 suptpi17\n",
      "340 suptpi18\n",
      "341 suptpi19\n",
      "342 suptpi20\n",
      "343 suptpi21\n",
      "344 suptpi22\n",
      "345 apptpi\n",
      "346 statetpi\n",
      "347 othertpi\n",
      "348 Document Type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "art2     0\n",
       "art3     0\n",
       "art4     0\n",
       "art5     0\n",
       "art6     2\n",
       "art7     0\n",
       "art8     0\n",
       "art9     0\n",
       "art10    0\n",
       "art11    0\n",
       "art12    0\n",
       "art13    0\n",
       "art14    0\n",
       "art17    0\n",
       "art18    0\n",
       "art25    0\n",
       "art34    0\n",
       "art38    0\n",
       "art46    0\n",
       "Name: 51, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_df['country1'].unique() # 35 length\n",
    "\n",
    "# Column Index\n",
    "index = 0\n",
    "for x in business_df:\n",
    "    print(index, x)\n",
    "    index += 1\n",
    "\n",
    "# Article Violation Columns\n",
    "business_df.iloc[0, 18:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    no_violation  violation  total  percentage_violation\n",
      "Austria                        7          3     10              0.300000\n",
      "Belgium                       10          5     15              0.333333\n",
      "Switzerland                    3          7     10              0.700000\n",
      "Cyprus                         1          3      4              0.750000\n",
      "Germany                        9          3     12              0.250000\n",
      "Denmark                        0          1      1              1.000000\n",
      "Spain                          4          4      8              0.500000\n",
      "France                         6         20     26              0.769231\n",
      "Greece                         2         16     18              0.888889\n",
      "Italy                          1          5      6              0.833333\n",
      "Ireland                        2          0      2              0.000000\n",
      "Iceland                        0          1      1              1.000000\n",
      "Luxembourg                     0          0      0              0.000000\n",
      "Malta                          0          2      2              1.000000\n",
      "Norway                         5          2      7              0.285714\n",
      "Netherlands                    2          2      4              0.500000\n",
      "Portugal                       3          3      6              0.500000\n",
      "Sweden                        12          6     18              0.333333\n",
      "Finland                        2          3      5              0.600000\n",
      "Turkey                         2         20     22              0.909091\n",
      "United Kingdom                11         13     24              0.541667\n",
      "Albania                        0          0      0              0.000000\n",
      "Andorra                        0          2      2              1.000000\n",
      "Armenia                        0          1      1              1.000000\n",
      "Azerbaijan                     0          1      1              1.000000\n",
      "Bulgaria                       0          8      8              1.000000\n",
      "Croatia                        0          6      6              1.000000\n",
      "Czech Republic                 0          0      0              0.000000\n",
      "Estonia                        0          2      2              1.000000\n",
      "Georgia                        0          0      0              0.000000\n",
      "Hungary                        3          3      6              0.500000\n",
      "Latvia                         2          2      4              0.500000\n",
      "Liechtenstein                  1          0      1              0.000000\n",
      "Lithuania                      1          5      6              0.833333\n",
      "Moldova                        0          2      2              1.000000\n",
      "Poland                         0          0      0              0.000000\n",
      "Romania                        4         10     14              0.714286\n",
      "Russia                         6         21     27              0.777778\n",
      "San Marino                     0          0      0              0.000000\n",
      "Slovakia                       0          0      0              0.000000\n",
      "Slovenia                       0          0      0              0.000000\n",
      "North Macedonia                0          0      0              0.000000\n",
      "Ukraine                        0          3      3              1.000000\n",
      "Bosnia Herzegovina             0          0      0              0.000000\n",
      "Monaco                         0          0      0              0.000000\n",
      "Montenegro                     0          1      1              1.000000\n",
      "Serbia                         0          0      0              0.000000\n"
     ]
    }
   ],
   "source": [
    "#Business\n",
    "results = {country: {'no_violation': 0, 'violation': 0} for country in country_dict.values()}\n",
    "\n",
    "for country in country_dict.values():\n",
    "    country_df = business_df[business_df['country1'] == country]\n",
    "    \n",
    "    for col in country_df.iloc[:, 18:38]:\n",
    "        no_violations = (country_df[col] == 1).sum()\n",
    "        violations = (country_df[col] == 2).sum()\n",
    "        \n",
    "        results[country]['no_violation'] += no_violations\n",
    "        results[country]['violation'] += violations\n",
    "\n",
    "countries_violations = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "countries_violations['total'] = countries_violations['no_violation'] + countries_violations['violation']\n",
    "countries_violations['percentage_violation'] = countries_violations['violation'] / countries_violations['total']\n",
    "countries_violations['percentage_violation'] = countries_violations['percentage_violation'].fillna(0)\n",
    "\n",
    "print(countries_violations)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined GeoJSON Business saved to output\\combined.json\n"
     ]
    }
   ],
   "source": [
    "# Business\n",
    "data_dir = \"country_shp\"\n",
    "all_features = []\n",
    "\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(data_dir, json_file)\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        if 'features' in data:\n",
    "            all_features.extend(data['features'])\n",
    "\n",
    "# Add violation data to GeoJSON properties\n",
    "for feature in all_features:\n",
    "    country_name = feature['properties'].get('COUNTRY')\n",
    "    if country_name in countries_violations.index:\n",
    "        no_violation = countries_violations.loc[country_name, 'no_violation']\n",
    "        violation = countries_violations.loc[country_name, 'violation']\n",
    "        total = countries_violations.loc[country_name, 'total']\n",
    "        percentage_violation = countries_violations.loc[country_name, 'percentage_violation']\n",
    "\n",
    "        # Handle NaN values by skipping or setting default\n",
    "        feature['properties']['no_violation'] = int(no_violation) if pd.notna(no_violation) else None\n",
    "        feature['properties']['violation'] = int(violation) if pd.notna(violation) else None\n",
    "        feature['properties']['total'] = int(total) if pd.notna(total) else None\n",
    "        feature['properties']['percentage_violation'] = float(percentage_violation) if pd.notna(percentage_violation) else None\n",
    "\n",
    "combined_geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": all_features\n",
    "}\n",
    "\n",
    "output_dir = \"output\"\n",
    "output_file = os.path.join(output_dir, \"combined.json\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(combined_geojson, f, indent=4)\n",
    "\n",
    "print(f\"Combined GeoJSON Business saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values:\n"
     ]
    }
   ],
   "source": [
    "# Identify columns with NaN values in the DataFrame\n",
    "nan_columns = countries_violations.columns[countries_violations.isna().any()].tolist()\n",
    "\n",
    "# Print out the columns with NaN values\n",
    "print(\"Columns with NaN values:\")\n",
    "for col in nan_columns:\n",
    "    nan_rows = countries_violations[countries_violations[col].isna()]\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(nan_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Austria', 'Belgium', 'Switzerland', 'Cyprus', 'Germany', 'Denmark',\n",
       "       'Spain', 'France', 'Greece', 'Italy', 'Ireland', 'Iceland',\n",
       "       'Luxembourg', 'Malta', 'Norway', 'Netherlands', 'Portugal', 'Sweden',\n",
       "       'Finland', 'Turkey', 'United Kingdom', 'Albania', 'Andorra', 'Armenia',\n",
       "       'Azerbaijan', 'Bulgaria', 'Croatia', 'Czech Republic', 'Estonia',\n",
       "       'Georgia', 'Hungary', 'Latvia', 'Liechtenstein', 'Lithuania', 'Moldova',\n",
       "       'Poland', 'Romania', 'Russia', 'San Marino', 'Slovakia', 'Slovenia',\n",
       "       'North Macedonia', 'Ukraine', 'Bosnia Herzegovina', 'Monaco',\n",
       "       'Montenegro', 'Serbia'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_violations.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Serbia'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual country JSON files saved to countries_new_shp\n"
     ]
    }
   ],
   "source": [
    "# Load combined GeoJSON file\n",
    "combined_geojson_path = \"output/combined.json\"\n",
    "\n",
    "with open(combined_geojson_path, \"r\") as f:\n",
    "    combined_geojson = json.load(f)\n",
    "\n",
    "# Create a new directory to store individual country JSON files\n",
    "new_dir = \"countries_new_shp\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "# Extract and save each country's data\n",
    "for feature in combined_geojson['features']:\n",
    "    country_name = feature['properties'].get('COUNTRY')\n",
    "    if country_name:\n",
    "        country_data = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": [feature]\n",
    "        }\n",
    "        \n",
    "        country_file_path = os.path.join(new_dir, f\"{country_name}.json\")\n",
    "        \n",
    "        with open(country_file_path, \"w\") as f:\n",
    "            json.dump(country_data, f, indent=4)\n",
    "\n",
    "print(f\"Individual country JSON files saved to {new_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume echrdb_df is already defined\n",
    "# Years of interest\n",
    "years_interested = [1970, 1980, 1990, 2000, 2010]\n",
    "\n",
    "# Initialize the results dictionary\n",
    "results_by_year = {year: {country: {'no_violation': 0, 'violation': 0} for country in country_dict.values()} for year in years_interested}\n",
    "\n",
    "# Loop through each year\n",
    "for year in years_interested:\n",
    "    for country in country_dict.values():\n",
    "        country_df1 = echrdb_df[(echrdb_df['country1'] == country) & (echrdb_df['dtejmt'] <= year)]\n",
    "        \n",
    "        for col in country_df1.iloc[:, 19:37]:\n",
    "            no_violations = (country_df1[col] == 1).sum()\n",
    "            violations = (country_df1[col] == 2).sum()\n",
    "            \n",
    "            results_by_year[year][country]['no_violation'] += no_violations\n",
    "            results_by_year[year][country]['violation'] += violations\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "results_list = []\n",
    "for year in years_interested:\n",
    "    for country, data in results_by_year[year].items():\n",
    "        row = {\n",
    "            'country': country,\n",
    "            'year': year,\n",
    "            'no_violation': data['no_violation'],\n",
    "            'violation': data['violation'],\n",
    "            'total': data['no_violation'] + data['violation'],\n",
    "        }\n",
    "        results_list.append(row)\n",
    "\n",
    "countries_violations_by_year = pd.DataFrame(results_list)\n",
    "\n",
    "# Add population data\n",
    "country_pop_melted.columns = ['country', 'year', 'population']\n",
    "countries_violations_by_year = countries_violations_by_year.merge(country_pop_melted, on=['country', 'year'], how='left')\n",
    "\n",
    "print(countries_violations_by_year)\n",
    "\n",
    "print(countries_violations_by_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
